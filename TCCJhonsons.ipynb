{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh-Gabriel/Atrial-Enlargement-Detection/blob/main/TCCJhonsons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Nw5gojOnU2ZQ"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "from PIL import Image\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import cv2    as cv\n",
        "np.random.seed(42)\n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "import csv\n",
        "from itertools import islice\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RHuBbvoYosb",
        "outputId": "68109177-1d5d-4688-da98-aefabb272954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "memory.total [MiB]\n",
            "15109 MiB\n",
            "Tue Oct 18 23:05:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    32W /  70W |  14574MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#mount and defines\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "PATH             = 'drive/MyDrive/TCC/Dataset_V1/'\n",
        "norm             = \"N\"\n",
        "doente           = \"AAE_EP\"\n",
        "left             = \"Torax_LAT_E\"\n",
        "right            = \"Torax_LAT_D\"\n",
        "stop_n = stop_s  = 6\n",
        "# shape_w, shape_h = 2928, 2328\n",
        "shape_w, shape_h = 224,224\n",
        "# !git clone https://github.com/pjreddie/darknet.git\n",
        "# !cd drive/MyDrive/TCC/darknet; make\n",
        "!nvidia-smi --query-gpu=memory.total --format=csv\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Vik8wcj2804b"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from sklearn import metrics\n",
        "from tensorflow import keras\n",
        "from keras import layers \n",
        "\n",
        "def VGG16():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(input_shape=(shape_w, shape_h,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
        "    model.add(layers.Flatten(name='flatten'))\n",
        "    model.add(layers.Dense(256, activation='relu', name='fc1'))\n",
        "    model.add(layers.Dense(128, activation='relu', name='fc2'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid', name='output'))\n",
        "    model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gebriel = keras.applications.VGG16(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in gebriel.layers: \n",
        "  print(layer.name)\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = gebriel.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "xd = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
        "xd = tf.keras.layers.Dense(512, activation='relu')(xd)\n",
        "xd = tf.keras.layers.Dropout(0.5)(xd)\n",
        "xd = tf.keras.layers.Dense(2, activation='sigmoid')(xd)\n",
        "\n",
        "\n",
        "gemodelo = keras.Model(gebriel.input, xd)\n",
        "\n",
        "gemodelo.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97f5Z1N5_PAX",
        "outputId": "1dc3ae5d-2769-485c-8e0e-22f1548c396c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_13\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PS9fWMrqexM"
      },
      "outputs": [],
      "source": [
        "\"testes\"\n",
        "stop_l = openImgs(doente, left)\n",
        "stop_r = openImgs(doente, right)\n",
        "\n",
        "os.listdir('drive/MyDrive/TCC/Dataset_V1/AAE_EP')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGwfB8q2pSjw"
      },
      "source": [
        "Coloquei os defs e a chamada do join_open_files tudo junto, porque basicamente eles fazem uma coisa só que é o join_open_files e assim, não precisa ficar rodando os defs de novo toda vez que muda alguma coisa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Qcu9d-EEnhI0"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#1 chamada = 1 load em 1 classe com 1 lateralidade\n",
        "# retorno do vetor com os nomes das imagens\n",
        "def openImgs(classe,lateralidade):\n",
        "  r_v = [] \n",
        "  for subdir, dirs, files in os.walk(PATH+classe):\n",
        "    if (files and lateralidade in subdir):\n",
        "      r_v += [subdir+'/'+files[0]]\n",
        "  return shuffle(r_v, random_state = 42)\n",
        "\n",
        "#Retorna vetores para entrada de modelo\n",
        "#  X valores e Y labels\n",
        "#  Y label da imagem (1 = presença de doença)\n",
        "\n",
        "def join(lateralidade):\n",
        "  #print(\"Accessing files...\")\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for f in islice(openImgs(norm, lateralidade), 0, stop_n):\n",
        "      X += [f]\n",
        "      Y += [0]\n",
        "\n",
        "  for f in islice(openImgs(doente, lateralidade), 0, stop_s):\n",
        "      X += [f]\n",
        "      Y += [1]\n",
        "  return X,Y\n",
        "\n",
        "def join_open_files(lateralidade=left, reshape=True):\n",
        "  X, y = join(lateralidade)\n",
        "  Xl = []\n",
        "  for i in X:\n",
        "    # cv2_imshow(cv.imread(i, 0))\n",
        "    if reshape:\n",
        "      Xl.append(cv.resize(cv.imread(i), (shape_w, shape_h)))\n",
        "    else:\n",
        "      Xl.append(cv.imread(i))\n",
        "  return np.array(Xl), np.array(y)\n",
        "\n",
        "X, y = join_open_files() #Coloca as imagens já abertas nos vetores de 'treino e teste'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0bk7cY0wZN7"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(X[0])\n",
        "# cv2_imshow(cv.resize(X[0], (2500, 2500)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJK-CxEOUE8N"
      },
      "source": [
        "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
        "(arrumei o erro dando um resize e mudando a escala de cor na hora de abrir a imagen no join_open_files, depois disso dá um outro erro no fit dizendo que a dimensão tinha que ser 2 e é 3. Pra arrumar o erro de dimensão, forcei um shape e rashape no X.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHU0MqZBoJwa"
      },
      "outputs": [],
      "source": [
        "print(\"Size da lista X \" + str(len(X)))\n",
        "print(\"Size do X pro split \" + str(np.array(X).shape))\n",
        "print(\"Size do reshape: \", str(np.array(X).reshape((nsamples,nx*ny)).shape));\n",
        "\n",
        "# for x in X:\n",
        "#   print(array(x[0]));\n",
        "\n",
        "# cv2_imshow(X[5])\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "jG3sNXWQAPYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4934d19-3cf3-48d8-c141-4d4a2fe6b87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 224, 224, 3)\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n"
          ]
        }
      ],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)\n",
        "# clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "# clf.score(X_test, y_test)\n",
        "from sklearn import svm\n",
        "#Leave one patient out using SVC from above\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "def LOO(clf, X, y):\n",
        "  loo = LeaveOneOut()\n",
        "  loo.get_n_splits(X)\n",
        "  print(X.shape)\n",
        "  nsamples, nx, ny, channels = X.shape\n",
        "  score = 0\n",
        "  # print(X[:4])\n",
        "  for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    clf.fit(X_train, y_train)\n",
        "    score = clf.evaluate(X_test, y_test)\n",
        "    # print(score)\n",
        "  # print(score/12)\n",
        "  # return \"2\", \"2\", \"2\", \"2\"\n",
        "  return X_train, X_test, y_train, y_test\n",
        "  \n",
        "\n",
        "X_train, X_test, y_train, y_test = LOO(gemodelo, X, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_qqVsTKEzBG"
      },
      "source": [
        "Verificar pra fazer algo customizado e alterar o classiicador por meio de um laço, fica bala\n",
        "\n",
        "Antes tava fazendo 50% treino e 50% teste, por isso o 0.333333..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDQbuCziLWKQ"
      },
      "source": [
        "> Mount e Defines\n",
        "\n",
        ">  Funções que abrem a imagem\n",
        "\n",
        "> *   openImgs()\n",
        "*   join()\n",
        "*   joi_open_file()\n",
        "\n",
        "> Teste utilizando uma Support Vector Classifier(SVC) linear\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array;\n",
        "\n",
        "gebriel = keras.applications.VGG16(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in gebriel.layers: \n",
        "  print(layer.name)\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = gebriel.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "xd = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
        "xd = tf.keras.layers.Dense(512, activation='relu')(xd)\n",
        "xd = tf.keras.layers.Dropout(0.5)(xd)\n",
        "xd = tf.keras.layers.Dense(2, activation='sigmoid')(xd)\n",
        "\n",
        "\n",
        "gemodelo = keras.Model(gebriel.input, xd)\n",
        "\n",
        "gemodelo.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "X, y = join_open_files() #Coloca as imagens já abertas nos vetores de 'treino e teste'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "score = 0\n",
        "gemodelo.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(array(y_train))\n",
        "\n",
        "# gemodelo.fit(X_train, y_train)\n",
        "vgg_classifier = gemodelo.fit(X_train,y_train, epochs = 10,verbose = 1)\n",
        "\n",
        "y_pred = gemodelo.predict(X_test)\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "\n",
        "# # import math\n",
        "# # print(math.ceil(y_pred))\n",
        "# # print(metrics.classification_report(y_test, y_pred))\n",
        "# #return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tBhtSyvrF5sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee47aaa-ded8-4e59-96fd-d1eb1c8b2a91"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_17\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n",
            "(8, 224, 224, 3) (8,)\n",
            "[0 1 0 1 1 0 0 0]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 728ms/step - loss: 42.4647 - accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 21.0823 - accuracy: 0.6250\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.1169 - accuracy: 0.8750\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0974 - accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 6.8093 - accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3.7122 - accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.0169 - accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.1596 - accuracy: 0.8750\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "[1 1 0 1]\n",
            "[[1.0000000e+00 8.2757252e-16]\n",
            " [1.0000000e+00 2.6523877e-22]\n",
            " [1.0000000e+00 7.3525314e-15]\n",
            " [9.9901462e-01 6.3832167e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "vf5Gk-Khje10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d939db7e-b9c0-4668-803f-ec3655f854eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 224, 224, 3) (6,)\n",
            "Epoch 1/6\n",
            "1/1 [==============================] - 1s 1s/step - loss: 13.8206 - accuracy: 0.0000e+00\n",
            "Epoch 2/6\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 31.1868 - accuracy: 0.6667\n",
            "Epoch 3/6\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 4984.9683 - accuracy: 0.3333\n",
            "Epoch 4/6\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 4.1007 - accuracy: 0.3333\n",
            "Epoch 5/6\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 4.2561 - accuracy: 0.3333\n",
            "Epoch 6/6\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 33.3102 - accuracy: 0.6667\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 10.0162 - accuracy: 0.3333\n",
            "=============gemodelo===========\n",
            "Epoch 1/6\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/6\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/6\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/6\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/6\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/6\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.1186 - accuracy: 0.8333\n",
            "Modelo <  [10.016236305236816, 0.3333333432674408]\n",
            "GeModelo <  [4.1186203956604, 0.8333333134651184]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "#1 chamada = 1 load em 1 classe com 1 lateralidade\n",
        "# retorno do vetor com os nomes das imagens\n",
        "def openImgs(classe,lateralidade):\n",
        "  r_v = [] \n",
        "  for subdir, dirs, files in os.walk(PATH+classe):\n",
        "    if (files and lateralidade in subdir):\n",
        "      r_v += [subdir+'/'+files[0]]\n",
        "  return shuffle(r_v, random_state = 42)\n",
        "\n",
        "#Retorna vetores para entrada de modelo\n",
        "#  X valores e Y labels\n",
        "#  Y label da imagem (1 = presença de doença)\n",
        "\n",
        "def join(lateralidade):\n",
        "  #print(\"Accessing files...\")\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for f in islice(openImgs(norm, lateralidade), 0, stop_n):\n",
        "      X += [f]\n",
        "      Y += [0]\n",
        "\n",
        "  for f in islice(openImgs(doente, lateralidade), 0, stop_s):\n",
        "      X += [f]\n",
        "      Y += [1]\n",
        "  return X, Y\n",
        "\n",
        "def join_open_files(lateralidade=left, reshape=True):\n",
        "  X, y = join(lateralidade)\n",
        "  Xl = []\n",
        "  for i in X:\n",
        "    if reshape:\n",
        "      Xl.append(cv.resize(cv.imread(i), (224, 224)))\n",
        "    else:\n",
        "      Xl.append(cv.imread(i))\n",
        "  return np.array(Xl), np.array(y)\n",
        "\n",
        "X, y = join_open_files() #Coloca as imagens já abertas nos vetores de 'treino e teste'\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)\n",
        "\n",
        "score = 0\n",
        "model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "# model.fit(X_train, y_train)\n",
        "# y_pred = model.predict(X_test)\n",
        "# print(y_test)\n",
        "clas = model.fit(X_train, y_train, epochs = 6, verbose=1)\n",
        "\n",
        "eval_modelo = model.evaluate(X_test, y_test)\n",
        "import time\n",
        "time.sleep(3)\n",
        "print(\"=============gemodelo===========\")\n",
        "gemodelo.fit(X_train, y_train, epochs = 6, verbose = 1)\n",
        "\n",
        "eval_gemodelo = gemodelo.evaluate(X_test, y_test)\n",
        "\n",
        "\n",
        "print(\"Modelo < \", eval_modelo)\n",
        "print(\"GeModelo < \", eval_gemodelo)\n",
        "\n",
        "\n",
        "# import math\n",
        "# print(math.ceil(y_pred))\n",
        "# print(metrics.classification_report(y_test, y_pred))\n",
        "# #return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}