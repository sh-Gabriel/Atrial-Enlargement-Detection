{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sh-Gabriel/Atrial-Enlargement-Detection/blob/main/TCCJhonsons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nw5gojOnU2ZQ"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "from PIL import Image\n",
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import cv2    as cv\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import csv\n",
        "from itertools import islice\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RHuBbvoYosb",
        "outputId": "08fa5ce7-3583-4297-9248-056d32c627d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "memory.total [MiB]\n",
            "15109 MiB\n",
            "Tue Oct  4 22:24:38 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#mount and defines\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "PATH            = 'drive/MyDrive/TCC/Dataset_V1/'\n",
        "norm            = \"N\"\n",
        "doente          = \"AAE_EP\"\n",
        "left            = \"Torax_LAT_E\"\n",
        "right           = \"Torax_LAT_D\"\n",
        "stop_n = stop_s = 6\n",
        "\n",
        "# !git clone https://github.com/pjreddie/darknet.git\n",
        "# !cd drive/MyDrive/TCC/darknet; make\n",
        "!nvidia-smi --query-gpu=memory.total --format=csv\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzIqqCsOlWUq"
      },
      "source": [
        "Falta descobrir como saporr de baixo funciona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC6W7X2dlEzT"
      },
      "outputs": [],
      "source": [
        "#Monta uma rede VGG16\n",
        "tf.keras.applications.vgg16.VGG16(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PS9fWMrqexM"
      },
      "outputs": [],
      "source": [
        "\"testes\"\n",
        "stop_l = openImgs(doente, left)\n",
        "stop_r = openImgs(doente, right)\n",
        "\n",
        "os.listdir('drive/MyDrive/TCC/Dataset_V1/AAE_EP')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGwfB8q2pSjw"
      },
      "source": [
        "Coloquei os defs e a chamada do join_open_files tudo junto, porque basicamente eles fazem uma coisa só que é o join_open_files e assim, não precisa ficar rodando os defs de novo toda vez que muda alguma coisa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcu9d-EEnhI0"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#1 chamada = 1 load em 1 classe com 1 lateralidade\n",
        "# retorno do vetor com os nomes das imagens\n",
        "def openImgs(classe,lateralidade):\n",
        "  r_v = [] \n",
        "  for subdir, dirs, files in os.walk(PATH+classe):\n",
        "    if (files and lateralidade in subdir):\n",
        "      r_v += [subdir+'/'+files[0]]\n",
        "  return shuffle(r_v, random_state = 42)\n",
        "\n",
        "#Retorna vetores para entrada de modelo\n",
        "#  X valores e Y labels\n",
        "#  Y label da imagem (1 = presença de doença)\n",
        "\n",
        "def join(lateralidade):\n",
        "  #print(\"Accessing files...\")\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for f in islice(openImgs(norm, lateralidade), 0, stop_n):\n",
        "      X += [f]\n",
        "      Y += [0]\n",
        "\n",
        "  for f in islice(openImgs(doente, lateralidade), 0, stop_s):\n",
        "      X += [f]\n",
        "      Y += [1]\n",
        "  return X,Y\n",
        "\n",
        "def join_open_files(lateralidade=left, reshape=True):\n",
        "  X, y = join(lateralidade)\n",
        "  Xl = []\n",
        "  for i in X:\n",
        "    # cv2_imshow(cv.imread(i, 0))\n",
        "    if reshape:\n",
        "      Xl.append(cv.resize(cv.imread(i, 0), (2928, 2328)))\n",
        "    else:\n",
        "      Xl.append(cv.imread(i,0))\n",
        "  return Xl, y\n",
        "\n",
        "X, y = join_open_files() #Coloca as imagens já abertas nos vetores de 'treino e teste'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0bk7cY0wZN7"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(X[0])\n",
        "# cv2_imshow(cv.resize(X[0], (2500, 2500)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJK-CxEOUE8N"
      },
      "source": [
        "ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.\n",
        "(arrumei o erro dando um resize e mudando a escala de cor na hora de abrir a imagen no join_open_files, depois disso dá um outro erro no fit dizendo que a dimensão tinha que ser 2 e é 3. Pra arrumar o erro de dimensão, forcei um shape e rashape no X.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHU0MqZBoJwa"
      },
      "outputs": [],
      "source": [
        "print(\"Size da lista X \" + str(len(X)))\n",
        "print(\"Size do X pro split \" + str(np.array(X).shape))\n",
        "print(\"Size do reshape: \", str(np.array(X).reshape((nsamples,nx*ny)).shape));\n",
        "\n",
        "# for x in X:\n",
        "#   print(array(x[0]));\n",
        "\n",
        "# cv2_imshow(X[5])\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG3sNXWQAPYG"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)\n",
        "# clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "# clf.score(X_test, y_test)\n",
        "from sklearn import svm\n",
        "#Leave one patient out using SVC from above\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "def LOO(clf, X, y):\n",
        "  loo = LeaveOneOut()\n",
        "  loo.get_n_splits(X)\n",
        "  nsamples, nx, ny = np.array(X).shape\n",
        "  score = 0\n",
        "  # print(X[:4])\n",
        "  for train_index, test_index in loo.split(X):\n",
        "    X_train, X_test = np.array(X).reshape((nsamples,nx*ny))[train_index], np.array(X).reshape((nsamples,nx*ny))[test_index]\n",
        "    y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
        "    clf.fit(X_train, y_train)\n",
        "    score += clf.score(X_test, y_test)\n",
        "\n",
        "  print(score/12)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "  \n",
        "  \n",
        "X_train, X_test, y_train, y_test = LOO(svm.SVC(kernel='linear', C= 1), X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_qqVsTKEzBG"
      },
      "source": [
        "Verificar pra fazer algo customizado e alterar o classiicador por meio de um laço, fica bala\n",
        "\n",
        "Antes tava fazendo 50% treino e 50% teste, por isso o 0.333333..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDQbuCziLWKQ"
      },
      "source": [
        "> Mount e Defines\n",
        "\n",
        ">  Funções que abrem a imagem\n",
        "\n",
        "> *   openImgs()\n",
        "*   join()\n",
        "*   joi_open_file()\n",
        "\n",
        "> Teste utilizando uma Support Vector Classifier(SVC) linear\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vik8wcj2804b"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import random\n",
        "from sklearn.pipeline import Pipeline\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from sklearn import metrics\n",
        "from tensorflow import keras\n",
        "\n",
        "class CustomStandardScalerForCnn(TransformerMixin):\n",
        "    def __init__(self, with_mean=True, with_std=True):\n",
        "        self.with_mean = with_mean\n",
        "        self.with_std = with_std\n",
        "        self.mean_ = None\n",
        "        self.std_ = None\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        if self.with_mean:\n",
        "            self.mean_ = X.mean()\n",
        "        else:\n",
        "            self.mean_ = 0\n",
        "            \n",
        "        if self.with_std:\n",
        "            self.std_ = X.std()\n",
        "        else:\n",
        "            self.std_ = 1\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        if self.mean_ and self.std_:\n",
        "            return (X - self.mean_) / self.std_\n",
        "        else:\n",
        "            raise(\"CustomStandardScalerForCnn is not fitted\")\n",
        "            \n",
        "    def inverse_transform(self, X):\n",
        "        if self.with_std:\n",
        "            X *= self.std_\n",
        "        if self.with_mean:\n",
        "            X += self.mean_\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YRJ08DD08-Nu"
      },
      "outputs": [],
      "source": [
        "def VGG_inspired_build():\n",
        "    clf = keras.models.Sequential([\n",
        "        keras.layers.ZeroPadding2D((1,1), input_shape=(32, 32, 3)),\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.ZeroPadding2D((1,1)),\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)), # stride=2\n",
        "        keras.layers.ZeroPadding2D((1,1)),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.ZeroPadding2D((1,1)),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)), # stride=2\n",
        "        keras.layers.ZeroPadding2D((1,1)),\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.ZeroPadding2D((1,1)),\n",
        "        keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)), # stride=2\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(2048, activation='relu'),\n",
        "        keras.layers.Dropout(0.75),\n",
        "        keras.layers.Dense(2048, activation='relu'),\n",
        "        keras.layers.Dropout(0.75),\n",
        "        keras.layers.Dense(33, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    clf.compile(optimizer=keras.optimizers.Adam(),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return clf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array;\n",
        "\n",
        "gebriel = keras.applications.VGG16(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "for layer in gebriel.layers: \n",
        "  print(layer.name)\n",
        "  layer.trainable = False\n",
        "\n",
        "last_layer = gebriel.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "xd = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
        "xd = tf.keras.layers.Dense(512, activation='relu')(xd)\n",
        "xd = tf.keras.layers.Dropout(0.5)(xd)\n",
        "xd = tf.keras.layers.Dense(2, activation='sigmoid')(xd)\n",
        "\n",
        "\n",
        "gemodelo = keras.Model(gebriel.input, xd)\n",
        "\n",
        "gemodelo.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "X, y = join_open_files() #Coloca as imagens já abertas nos vetores de 'treino e teste'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "score = 0\n",
        "gemodelo.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(array(y_train))\n",
        "\n",
        "# gemodelo.fit(X_train, y_train)\n",
        "vgg_classifier = gemodelo.fit(X_train,y_train, epochs = 10,verbose = 1)\n",
        "\n",
        "y_pred = gemodelo.evaluate(X_test)\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "\n",
        "# import math\n",
        "# print(math.ceil(y_pred))\n",
        "# print(metrics.classification_report(y_test, y_pred))\n",
        "#return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBhtSyvrF5sk",
        "outputId": "d52d5186-0c5b-4636-d3da-3101edd27753"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_29\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n",
            "(8, 224, 224, 3) (8,)\n",
            "[0 1 0 1 1 0 0 0]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 673ms/step - loss: 10.6830 - accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 1.4901e-08 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 9.1217 - accuracy: 0.8750\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 1.5457 - accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 17.0013 - accuracy: 0.7500\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.2134 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.0628 - accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6069 - accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.6078 - accuracy: 0.8750\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.2436 - accuracy: 0.8750\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "[1 1 0 1]\n",
            "[0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vf5Gk-Khje10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d53b1f-64ae-4b12-e167-891b57e698d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 224, 224, 3) (6,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7fb8b672d0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 13.8206 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fba4344d4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 0 1]\n",
            "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 9.1440604e-37 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 1.0552981e-34 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 2.0365831e-37 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "#1 chamada = 1 load em 1 classe com 1 lateralidade\n",
        "# retorno do vetor com os nomes das imagens\n",
        "def openImgs(classe,lateralidade):\n",
        "  r_v = [] \n",
        "  for subdir, dirs, files in os.walk(PATH+classe):\n",
        "    if (files and lateralidade in subdir):\n",
        "      r_v += [subdir+'/'+files[0]]\n",
        "  return shuffle(r_v, random_state = 42)\n",
        "\n",
        "#Retorna vetores para entrada de modelo\n",
        "#  X valores e Y labels\n",
        "#  Y label da imagem (1 = presença de doença)\n",
        "\n",
        "def join(lateralidade):\n",
        "  #print(\"Accessing files...\")\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for f in islice(openImgs(norm, lateralidade), 0, stop_n):\n",
        "      X += [f]\n",
        "      Y += [0]\n",
        "\n",
        "  for f in islice(openImgs(doente, lateralidade), 0, stop_s):\n",
        "      X += [f]\n",
        "      Y += [1]\n",
        "  return X, Y\n",
        "\n",
        "def join_open_files(lateralidade=left, reshape=True):\n",
        "  X, y = join(lateralidade)\n",
        "  Xl = []\n",
        "  for i in X:\n",
        "    if reshape:\n",
        "      Xl.append(cv.resize(cv.imread(i), (224, 224)))\n",
        "    else:\n",
        "      Xl.append(cv.imread(i))\n",
        "  return np.array(Xl), np.array(y)\n",
        "\n",
        "X, y = join_open_files() #Coloca as imagens já abertas nos vetores de 'treino e teste'\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)\n",
        "\n",
        "score = 0\n",
        "model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_test)\n",
        "\n",
        "import math\n",
        "print(math.ceil(y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "#return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}